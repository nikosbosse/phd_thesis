# Evaluating forecasts using `scoringutils` in `R`
\label{sec:scoringutils}

The following Chapter presents `scoringutils`, an R package for evaluating forecasts. It explains the package functionality in detail and gives an overview of how practitioners can use it to evaluate and compare the performance of their forecasts. The package forms the basis for all forecast evaluations conducted in this thesis. 
`scoringutils` was developed to help address an acute need to understand the quality of the forecasts that were produced to inform the COVID response of public health institutions in the UK and abroad in 2020. It was continuously developed and refined to provide the tools needed to evaluate forecasts in an epidemiological context. In addition to the work presented in this PhD thesis, `scoringutils` also supports and facilitates the evaluations conducted by the US and European Forecast Hubs \citep{cramerEvaluationIndividualEnsemble2022, sherrattPredictivePerformanceMultimodel2022}, which both make use of the package. 

The scoring rules implemented in `scoringutils` are mostly not specific for forecasts of infectious diseases. Later, Chapter \ref{sec:LogTransformation} will go into more detail about how forecasts can be scored in a way that takes the particular characteristics of infectious disease forecasts better into account. 

\clearpage

\includepdf[pages=-]{papers/Research Paper Cover Sheet-18 Paper 1.docx.pdf}

\includepdf[pages=-]{papers/Paper-1-scoringutils.pdf}
