# Introduction {#intro}

## Motivation

<!-- Public health decision making in the context of infectious disease outbreaks requires making assumptions about the future. Accurate knowledge of what  -->

Modelling and forecasting of infectious diseases has in the past helped inform decision making in many different settings, e.g. for influenza [e.g. 1,2â€“4], dengue fever [e.g. 5,6,7], ebola [e.g. 8,9], chikungunya [e.g. 10,11]. During the COVID-19 epidemic, infectious disease modelling and forecasting played a particularly prominent role and garnered much interest from both decision makers and the general public (CITATION Cramer, Bracher, Hubs, Funk short term forecasts UK). 

The usefulness of a model or forecast, of course, depends on how accurately it is able to capture existing and future disease dynamics. Accuracy needs to be measured in order to be able to improve on existing models and forecasts or in order to make a decision about the degree to which they should influence decision making. When evaluating and comparing multiple models or forecasters, we can apply different metrics that assess predictive performance by comparing forecasts against observed data. Different metrics reward or penalise certain behaviours of forecasts differently and the the choice of the metric hence influences the result of the evaluation. It is therefore important to identify and use metrics that capture what forecast consumers actually care about. Past literature gives little guidance on what kinds of metric are especially appropriate in an epidemiological context and how to best present results. 

In the beginning of a new disease outbreak, data on the past accuracy of a forecaster or model is usually sparse as there are only few data points available. It is therefore important to establish an understanding of the underlying characteristics of different types of modelling and forecasting approaches that could help estimate a priori how trustworthy different predictions may be. A similar decision that needs to be made in the context of an early disease outbreak is to allocate resources to different types of modelling and forecasting approaches. Infectious disease modelling usually requires significant amount of resources in terms of time and effort. The resulting models normally represents a mixture of mathematical model assumptions and human judgement required to develop and tune the model. Given the high costs of developing models, it is useful to ask what mathematical modelling is able to add above human judgement alone. 

### Aims and objectives

The aim of this thesis is to help improve the usefulness of infectious disease forecasting in public health decision making by obtaining a deeper understanding of 
- what a 'good' forecast is in an epidemiological context and how we can identify useful forecasts
- how human judgement and mathematical modelling can best be used to obtain useful forecasts

It strives to accomplish this by fulfilling the following objectives: 

- Establish appropriate tools to evaluate predictions in `R` and review best practices in forecast evaluation (Paper 1)
- Develop tools to elicit human forecasts of infectious diseases, specifically COVID-19 (Paper 2)
- Analyse the role of human judgement in forecasting COVID-19 in Germany and Poland. Compare human judgement forecasts against model-based predictions and analyse the added benefit of human input over mathematical models (Paper 2)
- Improve current evaluation methods so that they are betters suited for evaluating forecasts in an epidemiological context. (Paper 3)

<!-- 2. Collect predictions of COVID-19 from humans in Germany, Poland. Compare these human -->
<!-- predictions against model-based forecasts to discern relative strengths and weaknesses of human -->
<!-- forecasters vs. model-based approaches -->
<!-- 3. Collect human forecasts of reported cases and deaths from COVID-19 in the UK as well as -->
<!-- human predictions of the effective reproduction number Rt to explore ways in which human -->
<!-- insight and epidemiological modelling can be combined -->

## Thesis outline

Chapter \@ref(background) gives background. 

- Forecast evaluation
- Human judgement forecasting
- Data that was used

Chapter \@ref(scoringutils) (Paper 1)

Chapter \@ref(GermanyPoland) (Paper 2)

- Application of the scoring rules explained in Chapter \@ref(scoringutils). 
- Development of a new app that collects probabilistic forecasts of humans
- Comparison humans vs. models

Chapter \@ref(LogTransform) (Paper 3)

- Answer to the inadequacies of scoring seen in Chapter 2. 
- Idea to transform forecasts before scoring

Potentially: Chapter on UK forecasting challenge
- does it replicate
- apply new scoring metric
- looking at way to combine Rt and human forecast. 

Chapter \@ref(Discussion) discusses results. 


## Code

- this thesis
- scoringutils
- crowdforecastr
- Germany and Poland
- Log or not
- UK forecasting challenge

## Additional achievements
- talks


Some text. 

<!-- Policy makers have recently started to rely on forecasts to make decisions. Accurate knowledge of the future is immensely valuable in all sorts of areas from farming to economics to public health. With the rise of the novel coronavirus SARS-CoV-2, statistical forecasting has gathered renewed attention. As the virus has spread over the globe, more and more research teams began forecasting the trajectory of the pandemic to help inform public policy. Several countries like the United States, Germany and the United Kingdom have therefore started to aggregate forecasts from different teams. Among these efforts, the US Forecast Hub [@umass-amherstinfluenzaforecastingcenterofexcellenceCovid19forecasthubOrg2020] is the largest and most visible. Its goal is to collect forecasts, to aggregate them, and to make them available to policy makers and the general public in the best possible way. Two questions have been at the centre of these efforts: The first is "how can we best evaluate the performance of a model?" The second is "how can we combine and aggregate different models to get the best possible prediction?". These two questions will be our guiding questions as well throughout this work.  -->








